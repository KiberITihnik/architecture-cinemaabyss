package main

import (
	"context"
	"encoding/json"
	"log"
	"net/http"
	"os"
	"time"

	"github.com/segmentio/kafka-go"
)

func main() {
	port := os.Getenv("PORT")
	if port == "" {
		port = "8082"
	}

	brokers := []string{"kafka:9092"}
	if envBrokers := os.Getenv("KAFKA_BROKERS"); envBrokers != "" {
		brokers = []string{envBrokers}
	}

	topics := []string{"movie-events", "user-events", "payment-events"}

	// –°–æ–∑–¥–∞—ë–º writers –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è brokers
	writers := make(map[string]*kafka.Writer)
	for _, topic := range topics {
		writers[topic] = kafka.NewWriter(kafka.WriterConfig{
			Brokers: brokers,
			Topic:   topic,
			// –£–±–∏—Ä–∞–µ–º RequiredAcks, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å —Ç–∏–ø–∞–º–∏
			// BatchTimeout –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å
			BatchTimeout: 1 * time.Second,
		})
	}

	// –ó–∞–ø—É—Å–∫ consumer'–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ; –º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å, –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ –ø—É–±–ª–∏–∫—É–µ—Ç–µ)
	startConsumers(brokers, topics)

	// –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–∞—Ä—à—Ä—É—Ç–æ–≤
	http.HandleFunc("/api/events/health", healthHandler)
	http.HandleFunc("/api/events/movie", publishHandler(writers["movie-events"], "movie-events"))
	http.HandleFunc("/api/events/user", publishHandler(writers["user-events"], "user-events"))
	http.HandleFunc("/api/events/payment", publishHandler(writers["payment-events"], "payment-events"))

	log.Printf("üöÄ Events service listening on :%s, publishing to Kafka at %v", port, brokers)
	log.Fatal(http.ListenAndServe(":"+port, nil))
}

// –ü–µ—Ä–µ–¥–∞—ë–º writer –Ω–∞–ø—Ä—è–º—É—é ‚Äî —á–∏—â–µ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ
func publishHandler(writer *kafka.Writer, topic string) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		var payload map[string]interface{}
		if err := json.NewDecoder(r.Body).Decode(&payload); err != nil {
			http.Error(w, "Invalid JSON", http.StatusBadRequest)
			return
		}

		eventBytes, _ := json.Marshal(payload)
		key := []byte(r.RemoteAddr)

		err := writer.WriteMessages(context.Background(), kafka.Message{
			Key:   key,
			Value: eventBytes,
		})
		if err != nil {
			log.Printf("‚ùå Failed to publish to %s: %v", topic, err)
			http.Error(w, "Publish failed", http.StatusInternalServerError)
			return
		}

		log.Printf("üì§ Published to %s: %s", topic, string(eventBytes))
		w.Header().Set("Content-Type", "application/json")
		w.WriteHeader(http.StatusCreated)
		json.NewEncoder(w).Encode(map[string]interface{}{
			"status": "success",
			"topic":  topic,
		})
	}
}

func healthHandler(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(http.StatusOK) // ‚Üê 200, –Ω–µ 201!
	w.Write([]byte(`{"status":true}`))
}

func startConsumers(brokers []string, topics []string) {
	for _, topic := range topics {
		go func(t string) {
			reader := kafka.NewReader(kafka.ReaderConfig{
				Brokers: brokers,
				Topic:   t,
				GroupID: "events-service-group",
			})
			log.Printf("‚úÖ Consumer started for topic: %s", t)
			for {
				msg, err := reader.ReadMessage(context.Background())
				if err != nil {
					log.Printf("‚ùå Error reading from %s: %v", t, err)
					time.Sleep(time.Second)
					continue
				}
				log.Printf("üì• [CONSUMED] Topic=%s | Key=%s | Value=%s",
					t, string(msg.Key), string(msg.Value))
			}
		}(topic)
	}
}